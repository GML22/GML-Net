\section{Przegląd literatury z zakresu detekcji budynków na zdjęciach lotniczych}

W~bieżącym rozdziale zaprezentowane zostaną wybrane badania naukowe z~zakresu detekcji budynków na zdjęciach lotniczych i~satelitarnych. Najważniejszym kluczem doboru artykułów badawczych była zbieżność tematyczna z~badaniem własnym, w~dalszej kolejności liczyła się deklarowana skuteczność opisywanych architektur oraz ich różnorodność tak by uzyskać jak najszerszy przegląd dostępnych metod oraz stosowanych hiperparametrów. W~ten sposób wyselekcjonowano siedem najbardziej istotnych artykułów z~dziedziny semantycznej segmentacji budynków na zdjęciach lotniczych i~satelitarnych. Artykuły te zostaną przeanalizowane w~bieżącym rozdziale w~kolejności zgodnej z~datami ich powstania. Wnioski z~tak przeprowadzonej analizy stanowić będą nieocenioną pomoc przy doborze właściwych hiperparametrów modelu tworzonego w~ramach badania własnego, który zostanie zaprezentowany w~kolejnym rozdziale bieżącej pracy.

Pierwszym analizowanym artykułem jest \emph{Satellite Imagery Feature Detection using Deep Convolutional Neural Network: A Kaggle Competition} \cite{iglovikov}. Jego autorami są  Iglovikov V., Mushinskiy S. i~Osin V., został on przez nich opublikowany w~czerwcu 2017~roku. W~artykule tym autorzy opisują stworzoną przez siebie sieć neuronową, którą zgłosili do konkursu \emph{DSTL Satellite Imagery Feature Detection challenge}. Celem tego konkursu było stworzenie modelu pozwalającego na efektywną detekcje dziesięciu różnych klas obiektów (w~tym budynków) na zdjęciach satelitarnych, o~rozdzielczości \emph{3600x3600}~pikseli i~dziewięciu kanałach przestrzennych. Rozwiązaniem zaproponowanym przez Iglovikova, Mushinskiy'ego. i~Osina była sieć o~architekturze \emph{U-Net} (z~funkcją aktywacji \emph{ELU}), trenowana przy pomocy funkcji straty zdefiniowanej jako różnica pomiędzy binarną entropią skrośną a~indeksem Jaccarda przez optymalizator \emph{Nadam} o~startowej stopie uczenia równej 0,001 i~momentum 0,9. Z~każdego zdjęcia satelitarnego, autorzy omawianego artykułu, wybierali losowo 128~fragmentów o~rozmiarach \emph{112x112}~pikseli, fragmenty te były następnie łączone w~partie po 400~na każdą epokę (trening trwał łącznie 100~epok). W~rezultacie autorzy uzyskali skuteczność w~detekcji budynków na poziomie \textbf{62,9\% \emph{IoU}}.

Kolejnym artykułem badawczym, który zostanie omówiony w~bieżącym rozdziale, jest \emph{Multi-Task Learning for Segmentation of Building Footprints with Deep Neural Networks} cite{bischke} opublikowany we wrześniu 2017~roku. Jego autorami są Bischke B., Helber P., Folz J., Borth D. oraz Dengel A., którzy pisząc go starali się zaadresować problem słabej jakości predykcji granic budynków przez sieci neuronowe, a ich rozwiązaniem tego problemu było zastosowanie nowatorskiej funkcji strat o nazwie \emph{Uncertainty Based Multi-Task Loss}. Funkcja te łączyła w~sobie nie tylko część semantyczną, ale też geometryczną, która miała dbać o~uzyskanie z~sieci predykcji maski o~odpowiednim, pożądanym kształcie. Jako zbiór danych autorzy omawianego artykułu wybrali \emph{Inria Aerial Image Labeling Dataset}, złożony ze 180~zdjęć lotniczych pięciu miast: Austin, Chicago, Hrabstwo Kitsap, Tyrol oraz Wiedeń (po 36~zdjęć każdego z miast). Zdjęcia te miały rozdzielczość \emph{5000x5000}~pikseli, trzy kanały przestrzenne, każde z~nich pokrywało teren o~powierzchni \emph{1500x1500} m$^2$. Zbiór walidacyjny został wydzielony ze zbioru treningowego poprzez wzięcie pięciu pierwszych zdjęć każdego z~miast. Każde zdjęcie lotnicze, autorzy omawianego w~tym akapicie artykułu, dzielili na 10~części, z~każdej z~tych części wybierali oni po cztery losowe fragmenty o~rozmiarach \emph{384x384}~pikseli. Fragmenty te były następnie poddawane augmentacji w~postaci losowego odwrócenia w~poziomie lub pionie, a~następnie były łączone w~partie po dziesięć sztuk i~w~takiej formie zasilały finalną sieć neuronową. Sieć zaproponowana przez Bischke, Helbera, Folza, Bortha i~Dengela miała architekturę \emph{SegNet} z~\emph{VGG-16} jako enkoderem, była trenowana przy pomocy optymalizatora \emph{SGD} z~początkową stopą uczenia równą 0,01, spadkiem wagi 0,0005 i~momentum 0,9. Tak skonstruowana sieć uzyskała skuteczność na poziomie \textbf{95,17\% \emph{OA}} oraz \textbf{70,14\% \emph{IoU}}.

W~artykule \emph{Automatic Building Segmentation of Aerial Imagery Using Multi-Constraint Fully Convolutional Networks} \cite{wu} z~marca 2018~roku, autorzy Wu G., Shao X., Guo Z., Chen Q., Yuan W., Shi X., Xu Y. i~Shibasaki R. prezentują sieć \emph{MC–FCN}, która jest ulepszeniem sieci \emph{U-Net} o~dodanie trzech dodatkowych wieloskalowych połączeń pomiędzy nadpróbkowanymi warstwami a~przykładami uczącymi, które są wykorzystywane w~czasie uczenia się modelu przy pomocy binarnej entropii skrośnej. Trenowanie tak powstałej sieci neuronowej było przeprowadzane na zbiorze zdjęć lotniczych o~wysokiej rozdzielczości wykonanych w~Nowej Zelandii dla ponad 18~km$^2$ terenu, w~tym 17~tysięcy budynków. Każde ze zdjęć lotniczych zostało w~pierwszej fazie podzielone na drobne fragmenty o~rozdzielczości \emph{224x224} pikseli, a~fragmenty te następnie posłużyły do zasilenia sieci \emph{MC-FCN} w~przykłady uczące. Łącznie trenowanie finalnego modelu trwało 100~epok i~zostało ono przeprowadzone przy pomocy optymalizatora \emph{Adam} o~startowej stopie uczenia równej 0,001. W~wyniku tak przeprowadzonych obliczeń autorzy artykułu \emph{Automatic Building Segmentation of Aerial Imagery Using Multi-Constraint Fully Convolutional Networks} uzyskali sieć neuronową o~skuteczności \textbf{97,6\% \emph{OA}} oraz \textbf{83,3\% \emph{IoU}}.

W~czerwcu 2018~roku opublikowany został kolejny artykuł podejmujący problematykę detekcji budynków na zdjęciach satelitarnych \emph{Building Detection from Satellite Imagery Using a~Composite Loss Function} \cite{golovanov}. Jego autorami byli Golovanov S., Kurbanov R., Artamonov A., Davydow A. oraz Nikolenko S., w~swoim artykule zaproponowali oni sieć neuronową o~architekturze \emph{LinkNet} \footnote{LinkNet ma architekturę niemal identyczną jak \emph{U-Net} tylko w miejsce konkatenacji warstw stosowane jest sumowanie.} z funkcją aktywacji \emph{ELU}, pretrenowanym enkoderem o~architekturze SE-ResNeXt-50 oraz funkcją strat zdefiniowaną jako ważona suma binarnej entropii skrośnej, \emph{Lovasz hinge loss} oraz błędu średniokwadratowego (o~wagach odpowiednio: 0,8, 0,2 i 10). Dodatkowo w~celu lepszej separacji budynków, autorzy omawianego w~bieżącym akapicie artykułu, przy liczeniu wartości \emph{BCE} zastosowali różne wagi dla poszczególnych pikseli, wzmacniając piksele blisko krawędzi budynków i~osłabiając piksele wewnątrz budynków. Cały model był trenowany na zbiorze danych o nazwie \emph{SpaceNet} złożonym z~trzykanałowych zdjęć satelitarnych takich miast jak Las Vegas, Paryż, Szanghaj czy Chartum. Z~każdego zdjęcia wycinane były fragmenty o~rozdzielczości \emph{256x256} pikseli, które podlegały standardowym augmentacją takim jak: rotacje, obroty, losowe skalowania, losowe przesunięcia oraz zmiany w~jasności i~kontraście. Tak przygotowane fragmenty zdjęć trafiały następnie w~partiach po 32 sztuki do sieci neuronowej, która podlegała trenowaniu przez 120~epok przez optymalizator \emph{SGD} z~momentum Nestorova równym 0,95 oraz początkową stopą uczenia na poziomie 0,01. Finalnie autorom artykułu \emph{Building Detection from Satellite Imagery Using a~Composite Loss Function} udało się uzyskać skuteczność modelu na poziomie \textbf{76,79\% \emph{F1S}}. 

Kolejnym ważnym artykułem, z~dziedziny semantycznej segmentacji budynków na zdjęciach lotniczych, który zostanie omówiony w~bieżącym rozdziale, jest artykuł \emph{Semantic Segmentation from Remote Sensor Data and the Exploitation of Latent Learning for Classification of Auxiliary Tasks} \cite{chatterjee}, którego autorami są Chatterjee B. oraz Poullis Ch. W~swoim artykule zaprezentowali oni sieć o~nazwie \emph{ICT-Net}, której bazową architekturę stanowiła sieć \emph{U-Net} uzupełniona o~bloki \emph{Dense} oraz \emph{Squeeze-and-Excitation}, w~celu poprawy jakości predykcji modelu. Tak skonstruowana sieć była trenowana na zbiorze \emph{Inria Aerial Image Labeling Dataset}, który podobnie jak w~artykule \emph{Multi-Task Learning for Segmentation of Building Footprints with Deep Neural Networks} został podzielony na zbiór walidacyjny oraz treningowy poprzez przypisanie do zbioru walidacyjnego pięciu pierwszych zdjęć każdego z~miast reprezentowanych w~tym zbiorze. Zdjęcia lotnicze pobrane ze zbioru \emph{Inria Aerial Image Labeling Dataset} poddawane były, przez autorów omawianego w~tym akapicie artykułu, wstępnej augmentacji (obroty / rotacje / skalowanie) a~następnie wycinano z~nich losowe fragmenty o~rozdzielczości \emph{256x256} pikseli, które trafiały do sieci \emph{ICT-Net} w~partiach po cztery sztuki. Trenowanie finalnego modelu było przeprowadzane na przestrzeni 100~epok, przy pomocy entropii skrośnej jako funkcji strat, za pomocą optymalizatora \emph{RMSProp} o~początkowej stopie uczenia równej 0,001. Co ciekawe autorzy omawianego w~tym akapicie artykułu, po przeprowadzeniu badań empirycznych, zdecydowali się na zastosowanie 40-sto procentowego progu definiującego czy dany piksel należy do budynku czy nie, co oznacza, iż kwalifikowali oni jako piksele należące do budynków wszystkie piksele, dla których sieć \emph{ICT-Net} zwróciła prawdopodobieństwo bycia budynkiem na poziomie 40\% lub wyższym (zazwyczaj w literaturze próg ten wynosi 50\%). Wyniki uzyskane przez Chatterjeego i~Poullisa na zbiorze \emph{Inria Aerial Image Labeling Dataset} przewyższały o~około 1,5\% najlepsze w~tamtym czasie wyniki i~do dnia pisania niniejszej pracy żadna inna sieć neuronowa nie uzyskała lepszych wyników dla tego zbioru (ang. \emph{state of art}) - te wyniki to \textbf{97,14\% \emph{OA}} oraz \textbf{80,32\% \emph{IoU}}.

W~kwietniu bieżącego roku, na łamach czasopisma \emph{IEEE Transactions on Geoscience and Remote Sensing} ukazał się artykuł \emph{Building Footprint Generation by Integrating Convolution Neural Network with Feature Pairwise Conditional Random Field (FPCRF)} \cite{zhu}, którego autorami są Zhu X., Li X. Q., Shi Y. oraz Huang X. W~artykule tym przedstawione jest kompleksowe podejście do detekcji budynków na zdjęciach lotniczych i~satelitarnych, które jest realizowane przy pomocy sieci \emph{FC-DenseNet} jako ekstraktora cech oraz metody \emph{Feature Pairwise Conditional Random Field} mającej służyć jako grafowa korelacja pikseli poprawiająca jakość semantycznej segmentacji poprzez generowanie ostrych krawędzi budynków. Autorzy testują stworzony przez siebie model na kilku wiodących zbiorach danych:  
\begin{itemize}
\item zdjęciach satelitarnych ze zbioru \emph{Planetscope} dla miast Monachium, Paryż, Rzym i~Zurych,
\item zdjęciach lotniczych \emph{ISPRS benchmark} dla miasta Poczdam,
\item zdjęciach satelitarnych \emph{WorldView3 } ze zbioru \emph{Dstl Kaggle dataset},
\item zdjęciach lotniczych \emph{Inria Aerial Image Labeling Dataset} dla miast Austin, Chicago, Kitsap County, Western Tyrol, and Vienna.
\end{itemize}

Dla każdego z~wyżej wymienionych zbiorów danych, autorzy omawianego w~bieżącym akapicie artykułu, uzyskują satysfakcjonujące wyniki. Stworzona przez nich sieć jest zasilana fragmentami zdjęć o~rozmiarze \emph{256x256} pikseli w~partiach po cztery sztuki. Jako funkcja straty wykorzystywany jest \emph{NLLLoss}, który jest minimalizowany przez optymalizator \emph{SGD} ze~startową stopą uczenia o~wartości 0,0001. Wyniki uzyskane przez Zhu X., Li X. Q., Shi Y. oraz Huang X.  dla zbioru \emph{Inria Aerial Image Labeling Dataset} przedstawiają się następująco: \textbf{95,81\% \emph{OA}}, \textbf{87,65\% \emph{F1S}} oraz \textbf{74,79\% \emph{IoU}}.

Ostatnim artykułem, który zostanie zaprezentowany w~bieżącym rozdziale, jest artykuł \emph{Polygonal Building Segmentation by Frame Field Learning} \cite{girard}. Artykuł ten został opublikowany w~kwietniu bieżącego roku, a~jego autorami są Girard N., Smirnov D., Solomon J. oraz Tarabalka Y. Autorzy Ci w~swoim artykule postanowili skupić się na nauczeniu sieci neuronowej nie tylko odpowiedniej klasyfikacji pikseli, ale również odpowiedniego dopasowania do ramek poszczególnych budynków (ang. \emph{frame field}). Takie rozwiązanie pozwoliło uzyskać predykcje z~modelu, które w~sposób efektywny mogły być konwertowane z~obrazów rastrowych do wielokątów (ang. \emph{polygon}), w~szczególności przy użyciu zaprezentowanego w~artykule algorytmu. Autorzy omawianego w~bieżącym akapicie artykułu jako wiodące architektury swojego modelu wybrali dwie sieci: \emph{U-Net} oraz \emph{DeepLabV3}, a~zdefiniowana przez nich funkcja straty stanowiła ważoną sumę binarnej entropii skrośnej oraz \emph{Dice Loss}. Trenowanie modelu odbywało się na zbiorze danych \emph{Inria Aerial Image Labeling Dataset}, gdzie z~każdego zdjęcia lotniczego wycinane były fragmenty o rozdzielczości  \emph{512x512} pikseli, które następnie były łączone w~partie po 16~sztuk i~w~takiej formie trafiały do finalnego modelu. Tak zdefiniowana sieć pozwoliła uzyskać autorom zadowalające dla nich wyniki na poziomie \textbf{78\% \emph{IoU}}.

\begin{landscape}
\begin{table}[!h]
\scriptsize
\begin{tabular}{M{0.5cm}M{5cm}M{3cm}M{2.7cm}M{3.5cm}M{2.7cm}M{1.5cm}M{2cm}}
\rowcolor{gray!50}
\textbf{L.p.} & \textbf{Tytuł artykułu} & \textbf{ Wiodący zbiór danych} & \textbf{Architektura modelu} & \textbf{Funkcja strat} & \textbf{Optymalizator} & \textbf{Rozmiar partii} & \textbf{Uzyskane wyniki} \\ \hline \\[0.1cm]

\textbf{1.} & \emph{Satellite Imagery Feature Detection using Deep Convolutional Neural Network: A Kaggle Competition} \cite{iglovikov} & \emph{DSTL Satellite Imagery} & U-Net & \makecell{Różnica pomiędzy: \\ BCE i IoU} & \makecell{Nadam \\ (LR: 0.001)} & 400 & \makecell{IoU: 62.9\%} \\[0.1cm] \\ \hline \\[0.1cm]

\textbf{2.} & \emph{Multi-Task Learning for Segmentation of Building Footprints with Deep Neural Networks} \cite{bischke}& \emph{Inria Aerial Image Labeling Dataset} & SegNet & Uncertainty Based Multi-Task Loss & \makecell{SGD \\ (LR: 0.001)} & 10 & \makecell{OA: 95.17\% \\ IoU: 70.14\%} \\[0.1cm] \\ \hline \\[0.1cm]

\textbf{3.} & \emph{Automatic Building Segmentation of Aerial Imagery Using Multi-Constraint Fully Convolutional Networks} \cite{wu} & \emph{Aerial images taken by Land Information of New Zealand} & MC–FCN U-Net & BCE & \makecell{Adam \\ (LR: 0.001)} & - & \makecell{OA: 97.60\% \\  IoU: 83.30\% } \\[0.1cm] \\ \hline \\[0.1cm]

\textbf{4.} & \emph{Building Detection from Satellite Imagery Using a Composite Loss Function} \cite{golovanov} & \emph{SpaceNet} &  \makecell{LinkNet \\ SE-ResNeXt-50} & \makecell{Ważona suma: \\ BCE, LHL i MSE} & \makecell{SGD \\ (LR: 0.01)} & 32 & \makecell{F1S: 76.79\%} \\[0.1cm] \\ \hline \\[0.1cm]

\textbf{5.} & \emph{Semantic Segmentation from Remote Sensor Data and the Exploitation of Latent Learning for Classification of Auxiliary Tasks} \cite{chatterjee} & \emph{Inria Aerial Image Labeling Dataset} & \makecell{ICT-Net} & CE & \makecell{RMSProp \\ (LR: 0.001)} & 4 & \makecell{OA: 97.14\% \\ IoU: 80.32\%} \\[0.1cm] \\ \hline \\[0.1cm]

\textbf{6.} & \emph{Building Footprint Generation by Integrating Convolution Neural Network with Feature Pairwise Conditional Random Field (FPCRF)} \cite{zhu} & \emph{Inria Aerial Image Labeling Dataset} & \makecell{FC-DenseNet \\ FPCRF} & NLLLoss & \makecell{SGD \\ (LR: 0.0001)} & 4 & \makecell{OA: 95.81\% \\  F1S: 87.65\% \\ IoU: 74.79\%} \\[0.1cm] \\ \hline \\[0.1cm]

\textbf{7.} & \emph{Polygonal Building Segmentation by Frame Field Learning} \cite{girard} & \emph{Inria Aerial Image Labeling Dataset} & \makecell{U-Net \\ DeepLabV3} & \makecell{Ważona suma: \\ BCE i  Dice Loss} & - & 64 & \makecell{IoU: 78.00\%} \\[0.1cm] \\ \hline \\[0.1cm]
\end{tabular}
\caption{Podsumowanie najważniejszych informacji pochodzących z~artykułów omówionych w~przeglądzie literatury}
 \label{tab:tabela1}
\end{table}
\end{landscape}

Tabela \ref{tab:tabela1} prezentuje podsumowanie najważniejszych informacji pochodzących z~omówionych w~bieżącym rozdziale artykułów naukowych z~zakresu detekcji budynków na zdjęciach lotniczych i~satelitarnych. Analiza literatury wskazuje, iż najczęściej wybieranym zbiorem danych, na którym przeprowadza się trenowanie modelu w~zadaniach detekcji budynków na zdjęciach lotniczych jest zbiór \emph{Inria Aerial Image Labeling Dataset}. Najczęściej stosowaną architekturą dla tego typu zadań jest architektura typu \emph{U-Net} oraz jej modyfikacje, najczęściej stosowaną funkcją straty jest binarna entropia skrośna, a najczęściej wykorzystywanym optymalizatorem jest \emph{SGD}. Dodatkowo warto zwrócić uwagę, iż w~przeważającej większości artykułów, rozdzielczość zdjęć uczących sieć neuronową wynosiła \emph{256x256} pikseli. Powyższe wnioski płynące z~zaprezentowanego w~niniejszym rozdziale przeglądu literatury posłużą w~dalszej części pracy do właściwego doboru początkowych wartości hiperparametrów tworzonej głębokiej sieci neuronowej.